 # Challenge 4: RAG & Factuality - Released on December 8, 2023, 9:00 AM PST

 <img width="850" alt="image" src="https://github.com/adventofgenai/challenges/assets/786476/90b4d27f-b682-4af8-aaf1-af0ac5b5134d">


**Objective:**

Develop a retrieval-based chat application using a vector database, integrating fact-checking via Prediction Guard APIs, within the Intel Developer Cloud (IDC) environment. Examples include PDF chat, Wiki Chat, image search with chat etc. Evaluation is based on the effective use of Prediction Guard LLM APIs and vector DB, factuality measure, and practical utility.

**Hashtags for submissions and quesions**: #challenge4sub , #question, announcements from org team will use hashtag #annoucements

**Hints:**

- Familiarize with Retrieval-Augmented Generation (RAG) from the available [notebook](https://docs.predictionguard.com/usingllms/augmentation#retrieval-augmentated-generation-rag), as well as the comprehensive descriptions found at  [llama-index](https://docs.llamaindex.ai/en/latest/getting_started/concepts.html)  and [langchain](https://python.langchain.com/docs/use_cases/question_answering/) , to understand how it effectively combines retrieval and generation models for generating responses.
- Dan from Prediction Guard has posted in the channel an excellent video on what RAG is and how to integrate it for this hack, please check it out.
- Choose a suitable vector database to ingest data (e.g., Wikipedia articles, PDF documents) for the application and ensure efficient querying â€“ for example [LanceDB](https://github.com/lancedb/lancedb), which is an embedded database you can install using pip.
- Incorporate Prediction Guard's [fact-checking features](https://docs.predictionguard.com/output/checks) for verifying information accuracy.
- Utilize the LLM API for generating coherent and contextually appropriate responses.
- Test different configurations of the LLM API for optimal response generation.
- Focus on the chat application's user experience, making it intuitive and practical for real-world scenarios.

**Resources:** 
- GenAI Notebooks that are available on [IDC](https://github.com/rahulunair/genAI)
- Advent of GenAI Resources [page](https://github.com/adventofgenai/resources)
- General docs on using LLMs learning pathways are [here](https://docs.predictionguard.com/usingllms)
- Specific notebook and example of RAG with Prediction Guard can be found [here](https://docs.predictionguard.com/usingllms/augmentation#retrieval-augmentated-generation-rag),
- Example of doing factuality checking with Prediction Guard is [here](https://docs.predictionguard.com/reference/factuality)

**Technical Setup:** Configure an embedded vector database like LanceDB for data retrieval and integrate Prediction Guard's LLM APIs and fact-checking features. Set up and customize the RAG model within the Jupyter Notebook to combine retrieval and generation for chat responses.

**Documentation:** Document the development process, challenges faced, and insights gained.

**Difficulty:** Advanced
